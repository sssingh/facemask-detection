{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure the folders and move images to make them ready for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs(dir_paths):\n",
    "    for dir_path in dir_paths:\n",
    "        try:\n",
    "            os.makedirs(dir_path)\n",
    "        except:\n",
    "            print(f'{dir_path} already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\flatten_raw_dataset already exists\n",
      "data\\flatten_raw_dataset\\real_with_mask already exists\n",
      "data\\flatten_raw_dataset\\real_without_mask already exists\n",
      "data\\flatten_raw_dataset\\simulated_with_mask already exists\n",
      "data\\flatten_raw_dataset\\simulated_without_mask already exists\n"
     ]
    }
   ],
   "source": [
    "# Original dataset\n",
    "orig_raw_base_path = os.path.join('data', 'raw_dataset')  \n",
    "# Raw dataset with all images under one directory\n",
    "flat_raw_base_path = os.path.join('data', 'flatten_raw_dataset') \n",
    "# Create raw_dataset directory if it doesn't exists\n",
    "create_dirs([flat_raw_base_path])\n",
    "# Create sub-directories if they don't exist in destination path\n",
    "sub_dirs = [os.path.join(flat_raw_base_path, 'real_with_mask'), \n",
    "            os.path.join(flat_raw_base_path, 'real_without_mask'),\n",
    "            os.path.join(flat_raw_base_path, 'simulated_with_mask'), \n",
    "            os.path.join(flat_raw_base_path, 'simulated_without_mask')]\n",
    "create_dirs(sub_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real with and without masks images under raw dataset are under various subdirectories \n",
    "# We need to move all imgaes to a single directory and rename them\n",
    "image_num = 0\n",
    "sub_dirs = ['real_with_mask', \n",
    "            'real_without_mask',\n",
    "            'simulated_with_mask', \n",
    "            'simulated_without_mask']\n",
    "\n",
    "for dir_num, sub_dir_1 in enumerate(sub_dirs):\n",
    "    image_num = 1\n",
    "    \n",
    "    src_dir_path = os.path.join(orig_raw_base_path, sub_dir_1)\n",
    "    dest_dir_path = os.path.join(flat_raw_base_path, sub_dir_1)\n",
    "    \n",
    "    # If real images sub-dir then images are stored under sub-diretories\n",
    "    # Get list of next level sub directories\n",
    "    if dir_num in [0, 1]:\n",
    "        src_dir_list = os.listdir(src_dir_path)\n",
    "        # Loop through each of subdirs and rename then copy images under it to destination\n",
    "        for sub_dir_2 in src_dir_list:\n",
    "            sub_dir_2_path = os.path.join(src_dir_path, sub_dir_2)\n",
    "            file_list = os.listdir(sub_dir_2_path)\n",
    "            # Loop through all the files in this sub_dir and copy to destination\n",
    "            for file in file_list:\n",
    "                old_file_name = os.path.join(os.path.join(src_dir_path, sub_dir_2) , file)\n",
    "                _, extension = os.path.splitext(old_file_name)\n",
    "                new_file_name = os.path.join(dest_dir_path, str(image_num) + extension)\n",
    "                shutil.copy(old_file_name, new_file_name)\n",
    "                image_num += 1\n",
    "\n",
    "                \n",
    "    # If simulated image dirs then just rename and copy the images to destination\n",
    "    else:\n",
    "        # Loop through all the files in this sub_dir and copy to destination\n",
    "        file_list = os.listdir(src_dir_path)\n",
    "        for file in file_list:\n",
    "            old_file_name = os.path.join(src_dir_path, file)\n",
    "            _, extension = os.path.splitext(old_file_name)\n",
    "            new_file_name = os.path.join(dest_dir_path, str(image_num) + extension)\n",
    "            shutil.copy(old_file_name, new_file_name)\n",
    "            image_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Image sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for inspecting image sizes and dumping the size details of all images in a dataframe\n",
    "def get_image_size(image_dir):\n",
    "    # Get list of images in passed dir\n",
    "    image_list = os.listdir(image_dir)\n",
    "    # Loop through image list, extract sizes and store them in a dataframe\n",
    "    df = pd.DataFrame(columns=['name', 'height', 'width'])\n",
    "    for img_name in image_list:\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img_height, img_width = img.shape[0], img.shape[1]\n",
    "        df.loc[len(df)] = [img_name, img_height, img_width]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the Real Mask image sizes \n",
    "df = get_image_size(os.path.join(flat_raw_base_path, sub_dirs[0]))\n",
    "df.to_csv('RFMD_Mask_Sizes.csv')\n",
    "\n",
    "# Inspect the Real Without Mask image sizes \n",
    "df = get_image_size(os.path.join(flat_raw_base_path, sub_dirs[1]))\n",
    "df.to_csv('RFMD_Without_Mask_Sizes.csv')\n",
    "\n",
    "# Inspect the Simulated Mask image sizes\n",
    "df = get_image_size(os.path.join(flat_raw_base_path, sub_dirs[2]))\n",
    "df.to_csv('SFMD_Mask_Sizes.csv')\n",
    "\n",
    "# Inspect the Simulated Without Mask image sizes \n",
    "df = get_image_size(os.path.join(flat_raw_base_path, sub_dirs[3]))\n",
    "df.to_csv('SFMD_Without_Mask_Sizes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for storing processed images \n",
    "processed_data_base_path = os.path.join('data', 'processed_dataset')\n",
    "train_val_path = os.path.join(processed_data_base_path, 'train_val')\n",
    "train_val_mask_path = os.path.join(train_val_path, 'mask')\n",
    "train_val_nomask_path = os.path.join(train_val_path, 'nomask')\n",
    "test_path = os.path.join(processed_data_base_path, 'test')\n",
    "test_mask_path = os.path.join(test_path, 'mask')\n",
    "test_nomask_path = os.path.join(test_path, 'nomask')\n",
    "\n",
    "dirs = [processed_data_base_path, \n",
    "        train_val_path, train_val_mask_path, train_val_nomask_path,\n",
    "        test_path, test_mask_path, test_nomask_path]\n",
    "create_dirs(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for pre-processing the image\n",
    "def preprocess_image(src_path, dest_path, image_num, prefix):\n",
    "    image_list = os.listdir(src_path)\n",
    "    random.shuffle(image_list)\n",
    "    image_list = image_list[:image_num]\n",
    "    for image_name in image_list:\n",
    "        image_src_path = os.path.join(src_path, image_name)\n",
    "        image_dest_path = os.path.join(dest_path, prefix + image_name)\n",
    "        img = cv2.imread(image_src_path)\n",
    "        # Resize the images to 128x128, \n",
    "        img = cv2.resize(img,(224, 224), cv2.INTER_AREA)\n",
    "        # Save image in destination folder\n",
    "        cv2.imwrite(image_dest_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose all images from masked set (approx ~5,000 images)\n",
    "src_path = os.path.join('data', os.path.join('flatten_raw_dataset', 'real_with_mask'))\n",
    "image_num = len(os.listdir(src_path))\n",
    "dest_path = train_val_mask_path\n",
    "# Process and copy images and copy them to train_val folder\n",
    "preprocess_image(src_path, dest_path, image_num, 'A')\n",
    "\n",
    "# Choose all images from simulated masked set, process and copy them to train_val folder \n",
    "src_path = os.path.join('data', os.path.join('flatten_raw_dataset', 'simulated_with_mask'))\n",
    "image_num = len(os.listdir(src_path))\n",
    "# Process and copy images from source to destination folder\n",
    "preprocess_image(src_path, dest_path, image_num, 'B')\n",
    "#print(f'{src_path}\\n{dest_path}\\n{image_num}\\n')\n",
    "\n",
    "mask_image_num = len(os.listdir(dest_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose all images from simulated unmasked set\n",
    "src_path = os.path.join('data', os.path.join('flatten_raw_dataset', 'simulated_without_mask'))\n",
    "image_num = len(os.listdir(src_path))\n",
    "dest_path = train_val_nomask_path\n",
    "# Process and copy images from source to destination folder\n",
    "preprocess_image(src_path, dest_path, image_num, 'C')\n",
    "\n",
    "# Out of ~90,000 unmask images, choose number of images randomly so that they are equal to masked images\n",
    "src_path = os.path.join('data', os.path.join('flatten_raw_dataset', 'real_without_mask'))\n",
    "dest_path = train_val_nomask_path\n",
    "# Process and copy images from source to destination folder\n",
    "preprocess_image(src_path, dest_path, mask_image_num - image_num, 'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep 800 mask & unmask images for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Move 500 images randomly out of training & validation data. These will not be part of training data\n",
    "# Final models will be evalutaed on this unseen dataset\n",
    "#\n",
    "\n",
    "# Mask images\n",
    "image_num = 500\n",
    "src_path = train_val_mask_path\n",
    "dest_path = test_mask_path\n",
    "image_list = os.listdir(src_path)\n",
    "random.shuffle(image_list)\n",
    "for i in range(image_num):\n",
    "    src_file_path = os.path.join(src_path, image_list[i])\n",
    "    dest_file_path = os.path.join(dest_path, image_list[i])\n",
    "    shutil.move(src_file_path, dest_file_path)\n",
    "\n",
    "# No Mask images\n",
    "src_path = train_val_nomask_path\n",
    "dest_path = test_nomask_path\n",
    "image_list = os.listdir(src_path)\n",
    "random.shuffle(image_list)\n",
    "for i in range(image_num):\n",
    "    src_file_path = os.path.join(src_path, image_list[i])\n",
    "    dest_file_path = os.path.join(dest_path, image_list[i])\n",
    "    shutil.move(src_file_path, dest_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(os.path.join('data', 'flatten_raw_dataset_OLD'))\n",
    "# shutil.rmtree(os.path.join('data', 'processed_dataset'))\n",
    "#shutil.rmtree(os.path.join('data', 'processed_dataset_128'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
